debug_mode: false
src_lang: de
tgt_lang: en
dataset_name: wmt19_de_en
dataset_is_in_bpe: true
lowercase_data: true
pad_token: <pad>
bos_token: <bos>
eos_token: <eos>
unk_token: <unk>
propn_token: <propn>
max_sequence_length: 80
max_vocab_src: 50000
min_freq_src: 0
max_vocab_tgt: 50000
min_freq_tgt: 0
extract_unk_stats: false

model_name: sts
emb_dropout: 0.3
train_batch_size: 4500
valid_batch_size: 4500
encoder_emb_size: 512
encoder_hidden_size: 1024
encoder_layers: 1
encoder_dropout_rate: 0.1
decoder_emb_size: 512
decoder_hidden_size: 1024
decoder_layers: 1
decoder_dropout_rate: 0.1
out_dropout: 0.2
coverage_dropout: 0.2

maximum_decoding_length: 100
bahdanau_attention: true
coverage_required: true
coverage_lambda: 1.0

n_epochs: 6
init_optim: adagrad
init_learning_rate: 0.01
init_epochs: 0
optim: adam
learning_rate: 0.0002
learning_momentum: 0.9
grad_clip: true
max_grad_norm: 5.0
val_slices: 10
lr_decay_patience_steps: 5
lr_decay_factor: 0.9
lr_decay_threshold: 0.1
lr_decay_min: 0.00001

beam_size: 10
beam_search_length_norm_factor: 0.65
beam_search_coverage_penalty_factor: 0.4
checkpoint_name: seq2seq_wmt19_de_en.pt
